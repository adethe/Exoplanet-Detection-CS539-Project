{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15282711-31f2-469f-b235-f723c208a129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Exoplanet Detection Strategy Comparison Script...\n",
      "Loading training data from: exoTrain.csv\n",
      "Loading testing data from: exoTest.csv\n",
      "Data loaded successfully.\n",
      "Merging training and testing data...\n",
      "Combined dataset shape: (5657, 3198)\n",
      "\n",
      "Separating features/labels and splitting data...\n",
      "Combined dataset feature shape: (5657, 3197)\n",
      "Combined labels distribution:\n",
      "0    0.992576\n",
      "1    0.007424\n",
      "Name: proportion, dtype: float64\n",
      "Performing stratified train-test split (test_size=0.25)...\n",
      "Shape of new training features: (4242, 3197)\n",
      "Shape of new testing features: (1415, 3197)\n",
      "Class distribution in new training set:\n",
      "0    0.992692\n",
      "1    0.007308\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in new test set:\n",
      "0    0.992226\n",
      "1    0.007774\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "===== Processing Strategy: Row Scale =====\n",
      "Applying row-wise standard scaling...\n",
      "\n",
      "--- Training Logistic Regression ---\n",
      "Training completed in 22.09 seconds.\n",
      "\n",
      "--- Evaluating Logistic Regression (Row Scale) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.01 seconds.\n",
      "Balanced Accuracy: 0.6321\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      0.99      0.99      1404\n",
      "YES exoplanet (1)       0.20      0.27      0.23        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.60      0.63      0.61      1415\n",
      "     weighted avg       0.99      0.99      0.99      1415\n",
      "\n",
      "\n",
      "--- Training SVC ---\n",
      "Training completed in 51.26 seconds.\n",
      "\n",
      "--- Evaluating SVC (Row Scale) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 3.52 seconds.\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "--- Training Decision Tree ---\n",
      "Training completed in 33.73 seconds.\n",
      "\n",
      "--- Evaluating Decision Tree (Row Scale) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.02 seconds.\n",
      "Balanced Accuracy: 0.6307\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      0.99      0.99      1404\n",
      "YES exoplanet (1)       0.16      0.27      0.20        11\n",
      "\n",
      "         accuracy                           0.98      1415\n",
      "        macro avg       0.58      0.63      0.60      1415\n",
      "     weighted avg       0.99      0.98      0.99      1415\n",
      "\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Training completed in 3.16 seconds.\n",
      "\n",
      "--- Evaluating Random Forest (Row Scale) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.04 seconds.\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "===== Processing Strategy: Row Scale + Class Weight =====\n",
      "Applying row-wise standard scaling...\n",
      "\n",
      "--- Training Logistic Regression (Class Weights) ---\n",
      "Training completed in 15.27 seconds.\n",
      "\n",
      "--- Evaluating Logistic Regression (Row Scale + Class Weight) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.01 seconds.\n",
      "Balanced Accuracy: 0.7275\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       1.00      0.91      0.95      1404\n",
      "YES exoplanet (1)       0.05      0.55      0.08        11\n",
      "\n",
      "         accuracy                           0.91      1415\n",
      "        macro avg       0.52      0.73      0.52      1415\n",
      "     weighted avg       0.99      0.91      0.94      1415\n",
      "\n",
      "\n",
      "--- Training SVC (Class Weights) ---\n",
      "Training completed in 53.98 seconds.\n",
      "\n",
      "--- Evaluating SVC (Row Scale + Class Weight) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 4.12 seconds.\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "--- Training Decision Tree (Class Weights) ---\n",
      "Training completed in 7.21 seconds.\n",
      "\n",
      "--- Evaluating Decision Tree (Row Scale + Class Weight) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.02 seconds.\n",
      "Balanced Accuracy: 0.4932\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      0.99      0.99      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.98      1415\n",
      "        macro avg       0.50      0.49      0.49      1415\n",
      "     weighted avg       0.98      0.98      0.98      1415\n",
      "\n",
      "\n",
      "--- Training Random Forest (Class Weights) ---\n",
      "Training completed in 1.01 seconds.\n",
      "\n",
      "--- Evaluating Random Forest (Row Scale + Class Weight) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.06 seconds.\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "===== Processing Strategy: Col Scale + PCA =====\n",
      "Applying column-wise standard scaling and PCA...\n",
      "Shape after scaling: Train=(4242, 3197), Test=(1415, 3197)\n",
      "Shape after PCA: Train=(4242, 64), Test=(1415, 64)\n",
      "PCA Explained Variance Ratio (64 components): 0.9997\n",
      "\n",
      "--- Training Logistic Regression ---\n",
      "Training completed in 1.60 seconds.\n",
      "\n",
      "--- Evaluating Logistic Regression (Col Scale + PCA) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.00 seconds.\n",
      "Balanced Accuracy: 0.4996\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "--- Training SVC ---\n",
      "Training completed in 0.28 seconds.\n",
      "\n",
      "--- Evaluating SVC (Col Scale + PCA) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.03 seconds.\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "--- Training Decision Tree ---\n",
      "Training completed in 0.24 seconds.\n",
      "\n",
      "--- Evaluating Decision Tree (Col Scale + PCA) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.00 seconds.\n",
      "Balanced Accuracy: 0.4964\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      0.99      0.99      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.98      1415\n",
      "\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Training completed in 0.32 seconds.\n",
      "\n",
      "--- Evaluating Random Forest (Col Scale + PCA) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.18 seconds.\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "===== Processing Strategy: Col Scale + SMOTE =====\n",
      "Applying column-wise standard scaling and SMOTE...\n",
      "Shape after scaling: Train=(4242, 3197), Test=(1415, 3197)\n",
      "Applying SMOTE to training data...\n",
      "SMOTE resampling completed in 0.69 seconds.\n",
      "Training data shape after SMOTE: (8422, 3197)\n",
      "Training labels distribution after SMOTE:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Training Logistic Regression ---\n",
      "Training completed in 75.69 seconds.\n",
      "\n",
      "--- Evaluating Logistic Regression (Col Scale + SMOTE) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.01 seconds.\n",
      "Balanced Accuracy: 0.4294\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.97      0.04      0.08      1404\n",
      "YES exoplanet (1)       0.01      0.82      0.01        11\n",
      "\n",
      "         accuracy                           0.05      1415\n",
      "        macro avg       0.49      0.43      0.05      1415\n",
      "     weighted avg       0.96      0.05      0.08      1415\n",
      "\n",
      "\n",
      "--- Training SVC ---\n",
      "Training completed in 965.55 seconds.\n",
      "\n",
      "--- Evaluating SVC (Col Scale + SMOTE) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 41.34 seconds.\n",
      "Balanced Accuracy: 0.4986\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      0.99      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "--- Training Decision Tree ---\n",
      "Training completed in 44.64 seconds.\n",
      "\n",
      "--- Evaluating Decision Tree (Col Scale + SMOTE) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.02 seconds.\n",
      "Balanced Accuracy: 0.5326\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      0.97      0.98      1404\n",
      "YES exoplanet (1)       0.03      0.09      0.04        11\n",
      "\n",
      "         accuracy                           0.97      1415\n",
      "        macro avg       0.51      0.53      0.51      1415\n",
      "     weighted avg       0.99      0.97      0.98      1415\n",
      "\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Training completed in 4.54 seconds.\n",
      "\n",
      "--- Evaluating Random Forest (Col Scale + SMOTE) ---\n",
      "Predicting on test data...\n",
      "Prediction completed in 0.05 seconds.\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " NO exoplanet (0)       0.99      1.00      1.00      1404\n",
      "YES exoplanet (1)       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.99      1415\n",
      "        macro avg       0.50      0.50      0.50      1415\n",
      "     weighted avg       0.98      0.99      0.99      1415\n",
      "\n",
      "\n",
      "===== Overall Results Summary =====\n",
      "                  Model                  Strategy  Balanced Accuracy  \\\n",
      "0   Logistic Regression                 Row Scale           0.632090   \n",
      "1                   SVC                 Row Scale           0.500000   \n",
      "2         Decision Tree                 Row Scale           0.630666   \n",
      "3         Random Forest                 Row Scale           0.500000   \n",
      "4   Logistic Regression  Row Scale + Class Weight           0.727499   \n",
      "5                   SVC  Row Scale + Class Weight           0.500000   \n",
      "6         Decision Tree  Row Scale + Class Weight           0.493234   \n",
      "7         Random Forest  Row Scale + Class Weight           0.500000   \n",
      "8   Logistic Regression           Col Scale + PCA           0.499644   \n",
      "9                   SVC           Col Scale + PCA           0.500000   \n",
      "10        Decision Tree           Col Scale + PCA           0.496439   \n",
      "11        Random Forest           Col Scale + PCA           0.500000   \n",
      "12  Logistic Regression         Col Scale + SMOTE           0.429390   \n",
      "13                  SVC         Col Scale + SMOTE           0.498575   \n",
      "14        Decision Tree         Col Scale + SMOTE           0.532634   \n",
      "15        Random Forest         Col Scale + SMOTE           0.500000   \n",
      "\n",
      "    Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)  \n",
      "0              0.200000          0.272727            0.230769  \n",
      "1              0.000000          0.000000            0.000000  \n",
      "2              0.157895          0.272727            0.200000  \n",
      "3              0.000000          0.000000            0.000000  \n",
      "4              0.045113          0.545455            0.083333  \n",
      "5              0.000000          0.000000            0.000000  \n",
      "6              0.000000          0.000000            0.000000  \n",
      "7              0.000000          0.000000            0.000000  \n",
      "8              0.000000          0.000000            0.000000  \n",
      "9              0.000000          0.000000            0.000000  \n",
      "10             0.000000          0.000000            0.000000  \n",
      "11             0.000000          0.000000            0.000000  \n",
      "12             0.006637          0.818182            0.013168  \n",
      "13             0.000000          0.000000            0.000000  \n",
      "14             0.027027          0.090909            0.041667  \n",
      "15             0.000000          0.000000            0.000000  \n",
      "\n",
      "Results saved to plots\\model_comparison_results.csv\n",
      "\n",
      "Generating interactive comparison plots...\n",
      "Saved plot: plots\\balanced_accuracy_comparison.html\n",
      "Saved plot: plots\\f1-score_(class_1)_comparison.html\n",
      "Saved plot: plots\\recall_(class_1)_comparison.html\n",
      "Saved plot: plots\\precision_(class_1)_comparison.html\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os # For saving plots\n",
    "\n",
    "# Core ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier # Added Random Forest\n",
    "from imblearn.over_sampling import SMOTE # Added SMOTE\n",
    "# Metrics import\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "\n",
    "# Plotting library\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define paths to the dataset files\n",
    "TRAIN_CSV_PATH = 'exoTrain.csv'\n",
    "TEST_CSV_PATH = 'exoTest.csv'\n",
    "# Set a random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "# Define the proportion of data to use for the test set\n",
    "TEST_SET_SIZE = 0.25\n",
    "# PCA components (used in PCA strategy)\n",
    "PCA_COMPONENTS = 64 # Adjusted number of components\n",
    "# Directory to save plots\n",
    "PLOT_DIR = 'plots'\n",
    "os.makedirs(PLOT_DIR, exist_ok=True) # Create directory if it doesn't exist\n",
    "\n",
    "# --- Data Loading and Merging ---\n",
    "def load_and_merge_data(train_path, test_path):\n",
    "    \"\"\"Loads and merges training and testing data.\"\"\"\n",
    "    # (Same as in exoplanet_merged_split_v1)\n",
    "    try:\n",
    "        print(f\"Loading training data from: {train_path}\")\n",
    "        df_train = pd.read_csv(train_path)\n",
    "        print(f\"Loading testing data from: {test_path}\")\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        print(\"Data loaded successfully.\")\n",
    "        print(\"Merging training and testing data...\")\n",
    "        df_combined = pd.concat([df_train, df_test], ignore_index=True)\n",
    "        print(f\"Combined dataset shape: {df_combined.shape}\")\n",
    "        return df_combined\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Files not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data loading or merging: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Base Splitting Function ---\n",
    "def get_splits(df_combined, test_size=0.25, random_state=42):\n",
    "    \"\"\"Separates features/labels, converts labels, performs stratified split.\"\"\"\n",
    "    print(\"\\nSeparating features/labels and splitting data...\")\n",
    "    X_combined_raw = df_combined.drop('LABEL', axis=1)\n",
    "    y_combined_raw = df_combined['LABEL']\n",
    "    y_combined = (y_combined_raw - 1).astype(int).values # Convert labels 1,2 -> 0,1\n",
    "\n",
    "    print(f\"Combined dataset feature shape: {X_combined_raw.shape}\")\n",
    "    print(f\"Combined labels distribution:\\n{pd.Series(y_combined).value_counts(normalize=True)}\")\n",
    "\n",
    "    print(f\"Performing stratified train-test split (test_size={test_size})...\")\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "        X_combined_raw.values, y_combined,\n",
    "        test_size=test_size, random_state=random_state, stratify=y_combined\n",
    "    )\n",
    "    print(f\"Shape of new training features: {X_train_raw.shape}\")\n",
    "    print(f\"Shape of new testing features: {X_test_raw.shape}\")\n",
    "    print(f\"Class distribution in new training set:\\n{pd.Series(y_train).value_counts(normalize=True)}\")\n",
    "    print(f\"Class distribution in new test set:\\n{pd.Series(y_test).value_counts(normalize=True)}\")\n",
    "    return X_train_raw, X_test_raw, y_train, y_test\n",
    "\n",
    "# --- Preprocessing Strategy Functions ---\n",
    "\n",
    "def preprocess_row_scale(X_train_raw, X_test_raw):\n",
    "    \"\"\"Applies row-wise standard scaling independently to train and test sets.\"\"\"\n",
    "    print(\"Applying row-wise standard scaling...\")\n",
    "    # Scale training data rows\n",
    "    mean_train = np.mean(X_train_raw, axis=1, keepdims=True)\n",
    "    std_train = np.std(X_train_raw, axis=1, keepdims=True)\n",
    "    std_train[std_train == 0] = 1.0\n",
    "    X_train_scaled = (X_train_raw - mean_train) / std_train\n",
    "    # Scale test data rows\n",
    "    mean_test = np.mean(X_test_raw, axis=1, keepdims=True)\n",
    "    std_test = np.std(X_test_raw, axis=1, keepdims=True)\n",
    "    std_test[std_test == 0] = 1.0\n",
    "    X_test_scaled = (X_test_raw - mean_test) / std_test\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def preprocess_col_scale_pca(X_train_raw, X_test_raw, n_components=64, random_state=42):\n",
    "    \"\"\"Applies column-wise scaling (StandardScaler) and PCA.\"\"\"\n",
    "    print(\"Applying column-wise standard scaling and PCA...\")\n",
    "    # Column Scale (StandardScaler)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "    X_test_scaled = scaler.transform(X_test_raw)\n",
    "    print(f\"Shape after scaling: Train={X_train_scaled.shape}, Test={X_test_scaled.shape}\")\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_components, random_state=random_state)\n",
    "    X_train_processed = pca.fit_transform(X_train_scaled)\n",
    "    X_test_processed = pca.transform(X_test_scaled)\n",
    "    print(f\"Shape after PCA: Train={X_train_processed.shape}, Test={X_test_processed.shape}\")\n",
    "    print(f\"PCA Explained Variance Ratio ({n_components} components): {np.sum(pca.explained_variance_ratio_):.4f}\")\n",
    "    return X_train_processed, X_test_processed\n",
    "\n",
    "def preprocess_col_scale_smote(X_train_raw, X_test_raw, y_train, random_state=42):\n",
    "    \"\"\"Applies column-wise scaling (StandardScaler) and SMOTE to training data.\"\"\"\n",
    "    print(\"Applying column-wise standard scaling and SMOTE...\")\n",
    "    # Column Scale (StandardScaler)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "    X_test_scaled = scaler.transform(X_test_raw) # Scale test set too\n",
    "    print(f\"Shape after scaling: Train={X_train_scaled.shape}, Test={X_test_scaled.shape}\")\n",
    "\n",
    "    # SMOTE (only on training data)\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=random_state, k_neighbors=5)\n",
    "    print(\"Applying SMOTE to training data...\")\n",
    "    start_time = time.time()\n",
    "    X_train_processed, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"SMOTE resampling completed in {end_time - start_time:.2f} seconds.\")\n",
    "    print(f\"Training data shape after SMOTE: {X_train_processed.shape}\")\n",
    "    print(f\"Training labels distribution after SMOTE:\\n{pd.Series(y_train_resampled).value_counts(normalize=True)}\")\n",
    "    # IMPORTANT: Return resampled train data BUT original scaled test data and original test labels\n",
    "    return X_train_processed, X_test_scaled, y_train_resampled # Need resampled y_train for training\n",
    "\n",
    "# --- Model Training Functions ---\n",
    "# Added use_class_weight parameter\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, use_class_weight=False):\n",
    "    \"\"\"Trains Logistic Regression.\"\"\"\n",
    "    model_params = {\n",
    "        'solver': 'saga', 'max_iter': 1000, 'tol': 1e-3,\n",
    "        'random_state': RANDOM_STATE, 'n_jobs': -1, 'verbose': 0\n",
    "    }\n",
    "    if use_class_weight:\n",
    "        model_params['class_weight'] = 'balanced'\n",
    "        print(\"\\n--- Training Logistic Regression (Class Weights) ---\")\n",
    "    else:\n",
    "        print(\"\\n--- Training Logistic Regression ---\")\n",
    "\n",
    "    model = LogisticRegression(**model_params)\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "    return model\n",
    "\n",
    "def train_svc(X_train, y_train, use_class_weight=False):\n",
    "    \"\"\"Trains SVC.\"\"\"\n",
    "    model_params = {\n",
    "        'probability': True, 'random_state': RANDOM_STATE, 'cache_size': 500\n",
    "    }\n",
    "    if use_class_weight:\n",
    "        model_params['class_weight'] = 'balanced'\n",
    "        print(\"\\n--- Training SVC (Class Weights) ---\")\n",
    "    else:\n",
    "        print(\"\\n--- Training SVC ---\")\n",
    "\n",
    "    model = SVC(**model_params)\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "    return model\n",
    "\n",
    "def train_decision_tree(X_train, y_train, use_class_weight=False):\n",
    "    \"\"\"Trains a Decision Tree Classifier.\"\"\"\n",
    "    model_params = {'random_state': RANDOM_STATE}\n",
    "    if use_class_weight:\n",
    "        model_params['class_weight'] = 'balanced'\n",
    "        print(\"\\n--- Training Decision Tree (Class Weights) ---\")\n",
    "    else:\n",
    "        print(\"\\n--- Training Decision Tree ---\")\n",
    "\n",
    "    model = DecisionTreeClassifier(**model_params)\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "    return model\n",
    "\n",
    "def train_random_forest(X_train, y_train, use_class_weight=False):\n",
    "    \"\"\"Trains a Random Forest Classifier.\"\"\"\n",
    "    model_params = {'n_estimators': 100, 'random_state': RANDOM_STATE, 'n_jobs': -1}\n",
    "    if use_class_weight:\n",
    "        # balanced_subsample is often preferred for RF\n",
    "        model_params['class_weight'] = 'balanced_subsample'\n",
    "        print(\"\\n--- Training Random Forest (Class Weights) ---\")\n",
    "    else:\n",
    "        print(\"\\n--- Training Random Forest ---\")\n",
    "\n",
    "    model = RandomForestClassifier(**model_params)\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "    return model\n",
    "\n",
    "# --- Model Evaluation Function (Returns Metrics) ---\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\", strategy_name=\"Strategy\"):\n",
    "    \"\"\"Evaluates the model and returns key performance metrics.\"\"\"\n",
    "    print(f\"\\n--- Evaluating {model_name} ({strategy_name}) ---\")\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Strategy': strategy_name,\n",
    "        'Balanced Accuracy': np.nan,\n",
    "        'Precision (Class 1)': np.nan,\n",
    "        'Recall (Class 1)': np.nan,\n",
    "        'F1-Score (Class 1)': np.nan\n",
    "    }\n",
    "    try:\n",
    "        print(\"Predicting on test data...\")\n",
    "        start_time = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        print(f\"Prediction completed in {end_time - start_time:.2f} seconds.\")\n",
    "        y_pred = y_pred.astype(int)\n",
    "\n",
    "        # Calculate Balanced Accuracy\n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        results['Balanced Accuracy'] = bal_acc\n",
    "        print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "        # Get Classification Report as dict\n",
    "        report = classification_report(y_test, y_pred, labels=[0, 1],\n",
    "                                       target_names=[\"NO exoplanet (0)\", \"YES exoplanet (1)\"],\n",
    "                                       output_dict=True, zero_division=0)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        # Print formatted report for clarity\n",
    "        print(classification_report(y_test, y_pred, labels=[0, 1],\n",
    "                                    target_names=[\"NO exoplanet (0)\", \"YES exoplanet (1)\"],\n",
    "                                    zero_division=0))\n",
    "\n",
    "\n",
    "        # Extract metrics for the positive class ('YES exoplanet (1)')\n",
    "        if 'YES exoplanet (1)' in report:\n",
    "            results['Precision (Class 1)'] = report['YES exoplanet (1)']['precision']\n",
    "            results['Recall (Class 1)'] = report['YES exoplanet (1)']['recall']\n",
    "            results['F1-Score (Class 1)'] = report['YES exoplanet (1)']['f1-score']\n",
    "        else:\n",
    "             print(\"Warning: Class 1 not found in classification report results.\")\n",
    "\n",
    "\n",
    "        # Plot Confusion Matrix (Optional display, primarily returning metrics)\n",
    "        # print(\"\\nConfusion Matrix:\")\n",
    "        # cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"NO exoplanet (0)\", \"YES exoplanet (1)\"])\n",
    "        # fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        # disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "        # ax.set_title(f'{model_name} ({strategy_name}) Confusion Matrix')\n",
    "        # plt.tight_layout()\n",
    "        # plt.show() # This might block execution depending on environment\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during evaluation: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Exoplanet Detection Strategy Comparison Script...\")\n",
    "\n",
    "    # 1. Load and Merge Data\n",
    "    df_combined = load_and_merge_data(TRAIN_CSV_PATH, TEST_CSV_PATH)\n",
    "\n",
    "    if df_combined is not None:\n",
    "        # 2. Get Base Train/Test Splits (Raw Features)\n",
    "        X_train_raw, X_test_raw, y_train_base, y_test = get_splits(\n",
    "            df_combined, test_size=TEST_SET_SIZE, random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        # --- Define Strategies and Models ---\n",
    "        strategies = {\n",
    "            \"Row Scale\": {'preprocess': preprocess_row_scale, 'args': {}, 'use_class_weight': False, 'y_train_source': y_train_base},\n",
    "            \"Row Scale + Class Weight\": {'preprocess': preprocess_row_scale, 'args': {}, 'use_class_weight': True, 'y_train_source': y_train_base},\n",
    "            \"Col Scale + PCA\": {'preprocess': preprocess_col_scale_pca, 'args': {'n_components': PCA_COMPONENTS, 'random_state': RANDOM_STATE}, 'use_class_weight': False, 'y_train_source': y_train_base},\n",
    "            \"Col Scale + SMOTE\": {'preprocess': preprocess_col_scale_smote, 'args': {'random_state': RANDOM_STATE}, 'use_class_weight': False, 'y_train_source': None} # y_train comes from SMOTE func\n",
    "        }\n",
    "\n",
    "        models_to_train = {\n",
    "            \"Logistic Regression\": train_logistic_regression,\n",
    "            \"SVC\": train_svc,\n",
    "            \"Decision Tree\": train_decision_tree,\n",
    "            \"Random Forest\": train_random_forest\n",
    "        }\n",
    "\n",
    "        all_results = [] # List to store results dictionaries\n",
    "\n",
    "        # --- Run Experiments ---\n",
    "        for strategy_name, config in strategies.items():\n",
    "            print(f\"\\n===== Processing Strategy: {strategy_name} =====\")\n",
    "\n",
    "            # Apply preprocessing\n",
    "            preprocess_func = config['preprocess']\n",
    "            preprocess_args = config['args']\n",
    "            y_train_current = config['y_train_source'] # Base y_train unless overridden (like by SMOTE)\n",
    "\n",
    "            if strategy_name == \"Col Scale + SMOTE\":\n",
    "                 # SMOTE function returns resampled y_train\n",
    "                 X_train_processed, X_test_processed, y_train_current = preprocess_func(X_train_raw, X_test_raw, y_train_base, **preprocess_args)\n",
    "            else:\n",
    "                 # Other functions just process X\n",
    "                 X_train_processed, X_test_processed = preprocess_func(X_train_raw, X_test_raw, **preprocess_args)\n",
    "\n",
    "\n",
    "            # Train and evaluate models for this strategy\n",
    "            for model_name, train_func in models_to_train.items():\n",
    "                # Train model\n",
    "                model = train_func(X_train_processed, y_train_current, use_class_weight=config['use_class_weight'])\n",
    "\n",
    "                # Evaluate model\n",
    "                eval_results = evaluate_model(model, X_test_processed, y_test, model_name, strategy_name)\n",
    "                all_results.append(eval_results)\n",
    "\n",
    "\n",
    "        # --- Process and Visualize Results ---\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        print(\"\\n===== Overall Results Summary =====\")\n",
    "        print(results_df)\n",
    "\n",
    "        # Save results to CSV\n",
    "        results_csv_path = os.path.join(PLOT_DIR, 'model_comparison_results.csv')\n",
    "        results_df.to_csv(results_csv_path, index=False)\n",
    "        print(f\"\\nResults saved to {results_csv_path}\")\n",
    "\n",
    "        # Create Interactive Plots using Plotly\n",
    "        print(\"\\nGenerating interactive comparison plots...\")\n",
    "\n",
    "        metrics_to_plot = ['Balanced Accuracy', 'F1-Score (Class 1)', 'Recall (Class 1)', 'Precision (Class 1)']\n",
    "\n",
    "        for metric in metrics_to_plot:\n",
    "            fig = px.bar(results_df, x='Model', y=metric, color='Strategy',\n",
    "                         barmode='group', title=f'{metric} Comparison by Model and Strategy',\n",
    "                         labels={'Model': 'Classifier Model', metric: metric, 'Strategy': 'Preprocessing Strategy'},\n",
    "                         template='plotly_white') # Use a clean template\n",
    "            fig.update_layout(title_x=0.5) # Center title\n",
    "            plot_filename = os.path.join(PLOT_DIR, f'{metric.replace(\" \", \"_\").lower()}_comparison.html')\n",
    "            fig.write_html(plot_filename)\n",
    "            print(f\"Saved plot: {plot_filename}\")\n",
    "\n",
    "\n",
    "        print(\"\\nScript finished.\")\n",
    "    else:\n",
    "        print(\"\\nScript aborted due to data loading or merging errors.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddc53b-4bea-4535-9de8-2b742db2aa25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638efa6-9252-4143-a59b-ba98555386ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
